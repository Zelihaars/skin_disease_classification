{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":" !pip install split_folders","metadata":{"execution":{"iopub.status.busy":"2023-09-01T08:01:43.171353Z","iopub.execute_input":"2023-09-01T08:01:43.172446Z","iopub.status.idle":"2023-09-01T08:01:56.609551Z","shell.execute_reply.started":"2023-09-01T08:01:43.172400Z","shell.execute_reply":"2023-09-01T08:01:56.608355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python --version","metadata":{"execution":{"iopub.status.busy":"2023-09-01T08:01:56.613346Z","iopub.execute_input":"2023-09-01T08:01:56.613689Z","iopub.status.idle":"2023-09-01T08:01:57.582822Z","shell.execute_reply.started":"2023-09-01T08:01:56.613657Z","shell.execute_reply":"2023-09-01T08:01:57.581677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\nimport splitfolders\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-09-01T08:02:05.081044Z","iopub.execute_input":"2023-09-01T08:02:05.081453Z","iopub.status.idle":"2023-09-01T08:02:05.087251Z","shell.execute_reply.started":"2023-09-01T08:02:05.081414Z","shell.execute_reply":"2023-09-01T08:02:05.085545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from typing import Union\n\nclass ClassifyDatasets:\n    def __init__(self, datasets: str = None, input_dataset: str = None) -> None:\n        self.datasets = datasets\n        self.input_dataset = input_dataset  # extracting input data in here\n        if not os.path.exists(self.input_dataset):\n            os.makedirs(self.input_dataset)\n\n    def list_dirs_files(self, path: str = None) -> list:\n        return os.listdir(path)\n    \n    def unpack_archive(self, zip_path: str, extract_dir: str) -> None:\n        if os.path.splitext(zip_path)[1] in self.archived_extensions:\n            shutil.unpack_archive(zip_path, extract_dir=extract_dir)\n\n    def _process_csvfile(self, csvfile: str = None) -> tuple:\n        df = pd.read_csv(csvfile)\n        df = df.fillna('unknown')\n        columns = [\"isic_id\", \"diagnosis\", \"image_type\"]\n        df[\"isic_id\"] = df[\"isic_id\"].apply(lambda x: x + \".JPG\")\n        zipped_columns = tuple(df[columns].values)\n        return zipped_columns\n\n    def _copy_file(self, src_path: str, dest_path: str) -> bool:\n        try:\n            shutil.copy(src_path, dest_path)\n            return True\n        except FileNotFoundError:\n            print(f'ERROR: File not found error {src_path}')\n        except shutil.Error:\n            print(f'Destination file already exists {src_path}')\n            self.duplicate_count += 1\n        return False\n    \n    def _process_zipped_columns(self, zipped_columns: zip = None, image_files_list: list = []) -> int:\n        count = 0\n        self.duplicate_count = 0\n        for column in zipped_columns:\n            image_path = os.path.join(self.zipfile_path, column[0])\n            classified_dataset_path = os.path.join(self.input_dataset, column[1])\n            if os.path.exists(image_path) and column[2] == 'dermoscopic':\n                print(image_path)\n                if not os.path.exists(classified_dataset_path):\n                    os.makedirs(classified_dataset_path)\n                if self._copy_file(image_path, classified_dataset_path):\n                    count += 1\n        return count\n    \n    def classify_dataset_using_archived(self, image_files_list: list = []) -> Union[int, None]:\n        zipped_columns = self._process_csvfile(csvfile=self.csvfile)\n        # print(len(zipped_columns), len(image_files_list))\n        print(self.zipfile_path)\n        return self._process_zipped_columns(zipped_columns, image_files_list)\n\n    def filter_image_list(self, path: str = None):\n        if '.JPG' in path:\n            return path\n        return None\n    \n    def process_datasets(self, dataset_dir: str = None) -> Union[bool, int, None]:\n        if dataset_dir is None:\n            return False\n        dataset_with_metadata = os.path.join(self.datasets, dataset_dir)\n        list_dataset_files = self.list_dirs_files(dataset_with_metadata)\n        self.csvfile = None\n        self.zipfile_path = os.path.join(dataset_with_metadata, 'archive')\n        image_files_list = map(self.filter_image_list,\n                               self.list_dirs_files(self.zipfile_path))\n        image_files_list = [image_path for image_path in image_files_list\n                            if image_path is not None]\n        # print(len(image_files_list))\n        for file in list_dataset_files:\n            if os.path.splitext(file)[1] == '.csv':\n                self.csvfile = os.path.join(dataset_with_metadata, file)\n        if self.csvfile:\n            count = self.classify_dataset_using_archived(image_files_list)\n            return count\n        else:\n            print(f'Zip and CSV not found in {dataset_with_metadata}')\n        \n\n    def _main(self):\n        list_dirs_files = self.list_dirs_files(self.datasets)\n        result_processed_datasets = list(map(self.process_datasets,\n                                             list_dirs_files))\n        print(result_processed_datasets)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-01T08:02:09.469000Z","iopub.execute_input":"2023-09-01T08:02:09.469469Z","iopub.status.idle":"2023-09-01T08:02:09.503874Z","shell.execute_reply.started":"2023-09-01T08:02:09.469423Z","shell.execute_reply":"2023-09-01T08:02:09.502824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.getcwd()","metadata":{"execution":{"iopub.status.busy":"2023-09-01T08:02:30.575590Z","iopub.execute_input":"2023-09-01T08:02:30.575993Z","iopub.status.idle":"2023-09-01T08:02:30.585531Z","shell.execute_reply.started":"2023-09-01T08:02:30.575952Z","shell.execute_reply":"2023-09-01T08:02:30.584437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ../input/dermoscopic/datasets\ninput_folder_path = \"/kaggle/input/dermoscopic/datasets\"\ninput_dataset = 'input_dataset'","metadata":{"execution":{"iopub.status.busy":"2023-09-01T08:02:57.612541Z","iopub.execute_input":"2023-09-01T08:02:57.613687Z","iopub.status.idle":"2023-09-01T08:02:58.641825Z","shell.execute_reply.started":"2023-09-01T08:02:57.613633Z","shell.execute_reply":"2023-09-01T08:02:58.640453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd = ClassifyDatasets(datasets=input_folder_path,\n                      input_dataset=input_dataset)\nprint(cd._main())","metadata":{"execution":{"iopub.status.busy":"2023-09-01T08:03:21.528111Z","iopub.execute_input":"2023-09-01T08:03:21.528565Z","iopub.status.idle":"2023-09-01T08:04:51.693511Z","shell.execute_reply.started":"2023-09-01T08:03:21.528527Z","shell.execute_reply":"2023-09-01T08:04:51.692309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2023-08-29T04:50:57.717089Z","iopub.execute_input":"2023-08-29T04:50:57.717458Z","iopub.status.idle":"2023-08-29T04:50:57.723055Z","shell.execute_reply.started":"2023-08-29T04:50:57.717428Z","shell.execute_reply":"2023-08-29T04:50:57.721991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 15\nsecond_epochs = 15\ninput_location = \"../input/skin-diseases-image-dataset/IMG_CLASSES\"\noutput = \"output\" \nlist_of_folders = os.listdir(input_location)\nprint(list_of_folders)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T06:36:45.171392Z","iopub.execute_input":"2023-08-25T06:36:45.172131Z","iopub.status.idle":"2023-08-25T06:36:45.197218Z","shell.execute_reply.started":"2023-08-25T06:36:45.172094Z","shell.execute_reply":"2023-08-25T06:36:45.196174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_datasets(folders_to_copy, loc=input_location, output=output, is_temp_loc=True):\n    if is_temp_loc:\n        temp_loc = \"temp\"  # Temporary directory to hold the folders to copy\n        # Copy the selected folders to the temporary location\n        for folder_name in folders_to_copy:\n            source_folder = os.path.join(loc, folder_name)\n            destination_folder = os.path.join(temp_loc, folder_name)\n            shutil.copytree(source_folder, destination_folder)\n        # Use splitfolders to create the splits from the temporary location\n        splitfolders.ratio(temp_loc, output=output, seed=42, ratio=(0.80, 0.1, 0.1))\n        # Remove the temporary location\n        shutil.rmtree(temp_loc)\n    else:\n        splitfolders.ratio(loc, output=output, seed=42, ratio=(0.80, 0.1, 0.1))\n","metadata":{"execution":{"iopub.status.busy":"2023-08-18T11:22:19.933280Z","iopub.execute_input":"2023-08-18T11:22:19.934024Z","iopub.status.idle":"2023-08-18T11:22:19.942130Z","shell.execute_reply.started":"2023-08-18T11:22:19.933986Z","shell.execute_reply":"2023-08-18T11:22:19.940790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# removing first dir and then recreating dataset into dirs.\ndef generate_output_dir(output=output, exist_ok=True):\n#     shutil.rmtree(output)\n    os.makedirs(f'{output}', exist_ok=exist_ok)\n    os.makedirs(f'{output}/train', exist_ok=exist_ok)\n    os.makedirs(f'{output}/val', exist_ok=exist_ok)\n    os.makedirs(f'{output}/test', exist_ok=exist_ok)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T11:22:19.943981Z","iopub.execute_input":"2023-08-18T11:22:19.944443Z","iopub.status.idle":"2023-08-18T11:22:19.955689Z","shell.execute_reply.started":"2023-08-18T11:22:19.944406Z","shell.execute_reply":"2023-08-18T11:22:19.954643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Specify the folders you want to copy\n# folders_to_copy = [\"1. Eczema 1677\", \"3. Atopic Dermatitis - 1.25k\",\"8. Seborrheic Keratoses and other Benign Tumors - 1.8k\"]  # Replace with the actual folder names\nfolders_to_copy = list_of_folders[:]\nnum_classification = len(folders_to_copy)\ngenerate_output_dir()\ngenerate_datasets(folders_to_copy, loc=input_location, output=output, is_temp_loc=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-18T11:22:19.959354Z","iopub.execute_input":"2023-08-18T11:22:19.959649Z","iopub.status.idle":"2023-08-18T11:28:21.926190Z","shell.execute_reply.started":"2023-08-18T11:22:19.959622Z","shell.execute_reply":"2023-08-18T11:28:21.925129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> In kaggle we need to create a directory for our data after splitting but if we do this using jupyter notebook on our PC/laptop,we can just specify the input path and output path.","metadata":{}},{"cell_type":"code","source":"import os\nfor dirpath,dirname,filename in os.walk(f\"./{output}\"):\n    print(f\"There are {len(dirname)} and {len(filename)} in '{dirpath}'.\")","metadata":{"execution":{"iopub.status.busy":"2023-08-18T11:28:21.927775Z","iopub.execute_input":"2023-08-18T11:28:21.928842Z","iopub.status.idle":"2023-08-18T11:28:21.981529Z","shell.execute_reply.started":"2023-08-18T11:28:21.928800Z","shell.execute_reply":"2023-08-18T11:28:21.980477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> After modifying our input data and before the start of modelling its always best to visualize some random images of the dataset","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mping\nimport random\n\ndef plot_random_image(target_dir,target_class):\n    target_folder = target_dir + target_class\n    random_image = random.sample(os.listdir(target_folder),1)\n    img = mping.imread(target_folder + \"/\" + random_image[0])\n    plt.imshow(img)\n    plt.title(target_class)\n    plt.axis(\"off\");\n    return img\n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-21T05:13:57.079644Z","iopub.execute_input":"2023-08-21T05:13:57.080087Z","iopub.status.idle":"2023-08-21T05:13:57.088658Z","shell.execute_reply.started":"2023-08-21T05:13:57.080052Z","shell.execute_reply":"2023-08-21T05:13:57.087254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_random_figures(loc=[], output=output):\n    global num_classification\n    fig = plt.figure(figsize=(10, 7))\n    if num_classification > 4:\n        temp_num_clss = 4\n    else:\n        temp_num_clss = num_classification\n    for index in range(0, temp_num_clss):\n        fig.add_subplot(2,2,index + 1)\n        plot_random_image(target_dir = f\"./{output}/test/\",target_class = loc[index])\nplot_random_figures(loc=folders_to_copy, output=output)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T11:28:21.993353Z","iopub.execute_input":"2023-08-18T11:28:21.994007Z","iopub.status.idle":"2023-08-18T11:28:22.921210Z","shell.execute_reply.started":"2023-08-18T11:28:21.993963Z","shell.execute_reply":"2023-08-18T11:28:22.920260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ***Modelling***","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy(\"mixed_float16\")\n\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\",patience = 6,\n                                             min_delta = 0.0001)\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = \"val_loss\",factor = 0.2,\n                                                patience = 4,min_lr = 1e-7)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T11:28:22.935309Z","iopub.execute_input":"2023-08-18T11:28:22.936460Z","iopub.status.idle":"2023-08-18T11:28:22.950311Z","shell.execute_reply.started":"2023-08-18T11:28:22.936421Z","shell.execute_reply":"2023-08-18T11:28:22.949305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> When we use mixed_precision training the computation speed is increased by 3x times based on the GPU available. Mixed precision enables training using float16 half-precision variables whenever possible.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image_dataset_from_directory\n\ntrain_dir = f\"./{output}/train\"\ntest_dir =  f\"./{output}/test\"\nval_dir = f\"./{output}/val\"\n\ndef generate_train_test_validation(train_dir=train_dir, test_dir=test_dir, val_dir=val_dir):\n    train_data = image_dataset_from_directory(train_dir,label_mode = \"categorical\",\n                                              image_size = (224,224),batch_size = 32,\n                                             shuffle = True,seed = 42)\n    test_data = image_dataset_from_directory(test_dir,label_mode = \"categorical\",\n                                              image_size = (224,224),batch_size = 32,\n                                             shuffle = False,seed = 42)\n    val_data = image_dataset_from_directory(val_dir,label_mode = \"categorical\",\n                                          image_size = (224,224),batch_size = 32,\n                                         shuffle = False,seed = 42)\n    return train_data, test_data, val_data\ntrain_data, test_data, val_data = generate_train_test_validation(train_dir, test_dir, val_dir)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T11:28:22.952516Z","iopub.execute_input":"2023-08-18T11:28:22.952892Z","iopub.status.idle":"2023-08-18T11:28:25.025917Z","shell.execute_reply.started":"2023-08-18T11:28:22.952857Z","shell.execute_reply":"2023-08-18T11:28:25.024890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> image_dataset_from_directory() imports and converts our input data into tf.data.Dataset format and it is generally faster than ImageDataGenerator().","metadata":{}},{"cell_type":"code","source":"# class names in training datasets\nclass_names = train_data.class_names\nprint(len(class_names))\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T11:28:25.027632Z","iopub.execute_input":"2023-08-18T11:28:25.028500Z","iopub.status.idle":"2023-08-18T11:28:25.035355Z","shell.execute_reply.started":"2023-08-18T11:28:25.028459Z","shell.execute_reply":"2023-08-18T11:28:25.034274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def auto_tune_data(train_data, test_data, val_data):\n    train_data = train_data.prefetch(buffer_size = tf.data.AUTOTUNE)\n    test_data = test_data.prefetch(buffer_size = tf.data.AUTOTUNE)\n    val_data = val_data.prefetch(buffer_size = tf.data.AUTOTUNE)\n    return train_data, test_data, val_data\ntrain_data, test_data, val_data = auto_tune_data(train_data, test_data, val_data)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T11:28:25.037061Z","iopub.execute_input":"2023-08-18T11:28:25.038165Z","iopub.status.idle":"2023-08-18T11:28:25.049721Z","shell.execute_reply.started":"2023-08-18T11:28:25.038124Z","shell.execute_reply":"2023-08-18T11:28:25.048676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Data is prefetched to reduce computation time.","metadata":{}},{"cell_type":"code","source":"base_model = tf.keras.applications.EfficientNetB5(include_top = False)\nbase_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-08-18T11:28:25.051249Z","iopub.execute_input":"2023-08-18T11:28:25.051891Z","iopub.status.idle":"2023-08-18T11:28:30.256660Z","shell.execute_reply.started":"2023-08-18T11:28:25.051850Z","shell.execute_reply":"2023-08-18T11:28:30.255598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> First we are going to be training feature extractor EfficientNetB5 model. Feature extractor transfer learning involves using the pretrained weights of a model trained on another dataset similar to own for our own problem. Here the output layer of pretrained model is modified according our own problem.","metadata":{}},{"cell_type":"code","source":"for layer_num,layer in enumerate(base_model.layers):\n    print(layer_num,layer.name,layer.trainable)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T11:28:30.258347Z","iopub.execute_input":"2023-08-18T11:28:30.258742Z","iopub.status.idle":"2023-08-18T11:28:30.280921Z","shell.execute_reply.started":"2023-08-18T11:28:30.258702Z","shell.execute_reply":"2023-08-18T11:28:30.279845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> As we can see EfficientNetB5 consists of 575 layers without including the output layer and the most important thing to note among these layers is the rescaling layer present right after the input layer,this means that we dont have to rescale our data during preprocessing.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers.experimental import preprocessing\n\ndef create_data_aug_layer():\n    data_aug = tf.keras.Sequential([\n        preprocessing.RandomWidth(0.2),\n        preprocessing.RandomHeight(0.2),\n        preprocessing.RandomRotation(0.2),\n        preprocessing.RandomFlip(\"horizontal\")\n    ],name = \"data_augmentation_layer\")\n    return data_aug","metadata":{"execution":{"iopub.status.busy":"2023-08-18T11:28:30.282386Z","iopub.execute_input":"2023-08-18T11:28:30.283350Z","iopub.status.idle":"2023-08-18T11:28:30.307707Z","shell.execute_reply.started":"2023-08-18T11:28:30.283309Z","shell.execute_reply":"2023-08-18T11:28:30.306606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Data augmentation is used here to prevent overfitting, we can experiment without data augmentation and check whether the model overfits or not,but since we are using a transfer learning Architecture such as EfficientNet,its best to include data augmentation since the probability of our model overfitting is very high.","metadata":{}},{"cell_type":"code","source":"# build classification model\ndef build_classification_model(units=num_classification):\n    print(units)\n    data_aug = create_data_aug_layer()\n    inputs = layers.Input(shape = (224,224,3),name = \"input_layer\")\n    x = data_aug(inputs)\n    x = base_model(x)\n    x = layers.GlobalAvgPool2D(name = \"pooling_layer\")(x)\n    x = layers.Dense(32,activation = \"relu\",kernel_initializer = tf.keras.initializers.he_normal())(x)\n    x = layers.Dense(units)(x)\n    outputs = layers.Activation(\"softmax\",dtype = tf.float32)(x)\n    model = tf.keras.Model(inputs,outputs)\n    return model\nmodel = build_classification_model(units=num_classification)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T11:28:30.309242Z","iopub.execute_input":"2023-08-18T11:28:30.309727Z","iopub.status.idle":"2023-08-18T11:28:32.261688Z","shell.execute_reply.started":"2023-08-18T11:28:30.309688Z","shell.execute_reply":"2023-08-18T11:28:32.259854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-18T11:28:32.269826Z","iopub.execute_input":"2023-08-18T11:28:32.272959Z","iopub.status.idle":"2023-08-18T11:28:32.317603Z","shell.execute_reply.started":"2023-08-18T11:28:32.272911Z","shell.execute_reply":"2023-08-18T11:28:32.316502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer_num,layer in enumerate(model.layers):\n    print(layer_num,layer.name,layer.trainable,layer.dtype,layer.dtype_policy)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T11:28:32.318923Z","iopub.execute_input":"2023-08-18T11:28:32.319307Z","iopub.status.idle":"2023-08-18T11:28:32.348288Z","shell.execute_reply.started":"2023-08-18T11:28:32.319270Z","shell.execute_reply":"2023-08-18T11:28:32.347058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> We can clearly see here that mixed_precision policy is implemented and our EfficientNetB5 model is completely frozen. Now we can compile and fit our model.","metadata":{}},{"cell_type":"code","source":"def compile_model(model=model, learning_rate=0.001):\n    model.compile(\n        loss = tf.keras.losses.CategoricalCrossentropy(),\n        optimizer = tf.keras.optimizers.Adam(learning_rate),\n        metrics = [\"accuracy\"])\ncompile_model(model=model)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T11:28:32.349685Z","iopub.execute_input":"2023-08-18T11:28:32.350478Z","iopub.status.idle":"2023-08-18T11:28:32.380274Z","shell.execute_reply.started":"2023-08-18T11:28:32.350439Z","shell.execute_reply":"2023-08-18T11:28:32.379359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_1 = model.fit(train_data,epochs = epochs,steps_per_epoch = len(train_data),\n                     validation_data = val_data,validation_steps = int(0.25*len(val_data)),\n                     callbacks = [early_stop,reduce_lr])","metadata":{"execution":{"iopub.status.busy":"2023-08-18T11:28:32.381704Z","iopub.execute_input":"2023-08-18T11:28:32.382154Z","iopub.status.idle":"2023-08-18T12:02:21.897812Z","shell.execute_reply.started":"2023-08-18T11:28:32.382114Z","shell.execute_reply":"2023-08-18T12:02:21.896701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Validation Accuracy\",model.evaluate(val_data))\nprint(\"Testing Accuracy\",model.evaluate(test_data)) ","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:02:21.906672Z","iopub.execute_input":"2023-08-18T12:02:21.909756Z","iopub.status.idle":"2023-08-18T12:02:55.125527Z","shell.execute_reply.started":"2023-08-18T12:02:21.909711Z","shell.execute_reply":"2023-08-18T12:02:55.124445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_loss_curves(history):\n  \"\"\"\n  Returns separate loss curves for training and validation metrics.\n  \"\"\" \n  loss = history.history['loss']\n  val_loss = history.history['val_loss']\n\n  accuracy = history.history['accuracy']\n  val_accuracy = history.history['val_accuracy']\n\n  epochs = range(len(history.history['loss']))\n\n  # Plot loss\n  plt.plot(epochs, loss, label='training_loss')\n  plt.plot(epochs, val_loss, label='val_loss')\n  plt.title('Loss')\n  plt.xlabel('Epochs')\n  plt.legend()\n\n  # Plot accuracy\n  plt.figure()\n  plt.plot(epochs, accuracy, label='training_accuracy')\n  plt.plot(epochs, val_accuracy, label='val_accuracy')\n  plt.title('Accuracy')\n  plt.xlabel('Epochs')\n  plt.legend();","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:02:55.127532Z","iopub.execute_input":"2023-08-18T12:02:55.128037Z","iopub.status.idle":"2023-08-18T12:02:55.137289Z","shell.execute_reply.started":"2023-08-18T12:02:55.127993Z","shell.execute_reply":"2023-08-18T12:02:55.136256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_curves(history_1)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:02:55.139027Z","iopub.execute_input":"2023-08-18T12:02:55.140096Z","iopub.status.idle":"2023-08-18T12:02:55.704298Z","shell.execute_reply.started":"2023-08-18T12:02:55.140058Z","shell.execute_reply":"2023-08-18T12:02:55.702696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> * Training Accuracy - 74.4%\n> * Testing Accuracy  - 71.2%\n> * Validation Accuracy - 71.7%\n\n> Note: Specified number of epochs as 15 but training stopped at 12 and it wasn't beacuse of earlystopping callback,not sure why it stopped early, if you got any ideas please do mention it.","metadata":{}},{"cell_type":"markdown","source":"# Fine-Tuned EfficientNetB5","metadata":{}},{"cell_type":"code","source":"base_model.trainable = True\n\nfor layer in base_model.layers[:-30]:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:02:55.706147Z","iopub.execute_input":"2023-08-18T12:02:55.706806Z","iopub.status.idle":"2023-08-18T12:02:55.755712Z","shell.execute_reply.started":"2023-08-18T12:02:55.706763Z","shell.execute_reply":"2023-08-18T12:02:55.754796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Now in order to improve our model's performance we unfreeze the top 30 layers closer to the output layer and let them train on our data instead of using pre-trained weights.","metadata":{}},{"cell_type":"code","source":"for layer_num,layer in enumerate(model.layers):\n    print(layer_num,layer.name,layer.trainable,layer.dtype_policy)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:02:55.757005Z","iopub.execute_input":"2023-08-18T12:02:55.757371Z","iopub.status.idle":"2023-08-18T12:02:55.763938Z","shell.execute_reply.started":"2023-08-18T12:02:55.757334Z","shell.execute_reply":"2023-08-18T12:02:55.762782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer_num,layer in enumerate(base_model.layers):\n    print(layer_num,layer.name,layer.trainable)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:02:55.773439Z","iopub.execute_input":"2023-08-18T12:02:55.774029Z","iopub.status.idle":"2023-08-18T12:02:55.794294Z","shell.execute_reply.started":"2023-08-18T12:02:55.773991Z","shell.execute_reply":"2023-08-18T12:02:55.792980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compile_model(model=model, learning_rate=1e-4)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:02:55.795968Z","iopub.execute_input":"2023-08-18T12:02:55.796634Z","iopub.status.idle":"2023-08-18T12:02:55.829973Z","shell.execute_reply.started":"2023-08-18T12:02:55.796585Z","shell.execute_reply":"2023-08-18T12:02:55.829072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"second_iter_epochs = epochs + second_epochs\nhistory_2 = model.fit(train_data,epochs = second_iter_epochs,steps_per_epoch = len(train_data),\n                     initial_epoch = history_1.epoch[-1],\n                     validation_data = val_data,validation_steps = int(0.25*len(val_data)),\n                     callbacks = [early_stop,reduce_lr])","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:02:55.831657Z","iopub.execute_input":"2023-08-18T12:02:55.832034Z","iopub.status.idle":"2023-08-18T12:39:23.414685Z","shell.execute_reply.started":"2023-08-18T12:02:55.831994Z","shell.execute_reply":"2023-08-18T12:39:23.413388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Validation Accuracy\",model.evaluate(val_data))\nprint(\"Testing Accuracy\",model.evaluate(test_data))","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:39:23.417269Z","iopub.execute_input":"2023-08-18T12:39:23.418003Z","iopub.status.idle":"2023-08-18T12:39:59.807389Z","shell.execute_reply.started":"2023-08-18T12:39:23.417957Z","shell.execute_reply":"2023-08-18T12:39:59.806062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compare_historys(original_history, new_history, initial_epochs):\n    \"\"\"\n    Compares two model history objects.\n    \"\"\"\n    # Get original history measurements\n    acc = original_history.history[\"accuracy\"]\n    loss = original_history.history[\"loss\"]\n\n    print(len(acc))\n\n    val_acc = original_history.history[\"val_accuracy\"]\n    val_loss = original_history.history[\"val_loss\"]\n\n    # Combine original history with new history\n    total_acc = acc + new_history.history[\"accuracy\"]\n    total_loss = loss + new_history.history[\"loss\"]\n\n    total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n    total_val_loss = val_loss + new_history.history[\"val_loss\"]\n\n    print(len(total_acc))\n    print(total_acc)\n\n    # Make plots\n    plt.figure(figsize=(8, 8))\n    plt.subplot(2, 1, 1)\n    plt.plot(total_acc, label='Training Accuracy')\n    plt.plot(total_val_acc, label='Validation Accuracy')\n    plt.plot([initial_epochs-1, initial_epochs-1],\n              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n    plt.legend(loc='lower right')\n    plt.title('Training and Validation Accuracy')\n\n    plt.subplot(2, 1, 2)\n    plt.plot(total_loss, label='Training Loss')\n    plt.plot(total_val_loss, label='Validation Loss')\n    plt.plot([initial_epochs-1, initial_epochs-1],\n              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n    plt.legend(loc='upper right')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('epoch')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:39:59.809081Z","iopub.execute_input":"2023-08-18T12:39:59.810506Z","iopub.status.idle":"2023-08-18T12:39:59.824072Z","shell.execute_reply.started":"2023-08-18T12:39:59.810460Z","shell.execute_reply":"2023-08-18T12:39:59.823037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compare_historys(history_1,history_2,initial_epochs = 12)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:39:59.836757Z","iopub.execute_input":"2023-08-18T12:39:59.837152Z","iopub.status.idle":"2023-08-18T12:40:00.241736Z","shell.execute_reply.started":"2023-08-18T12:39:59.837114Z","shell.execute_reply":"2023-08-18T12:40:00.240728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> *  Training accuracy - 85.58%\n> *  Testing Accuracy - 77.08%\n> *  Validation Accuracy - 76.02%","metadata":{}},{"cell_type":"markdown","source":"# Model Evalutation","metadata":{}},{"cell_type":"code","source":"pred_probs = model.predict(test_data)\npred_probs[0]","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:40:00.243359Z","iopub.execute_input":"2023-08-18T12:40:00.243729Z","iopub.status.idle":"2023-08-18T12:40:16.554074Z","shell.execute_reply.started":"2023-08-18T12:40:00.243690Z","shell.execute_reply":"2023-08-18T12:40:16.552756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(pred_probs)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T13:17:29.470532Z","iopub.execute_input":"2023-08-18T13:17:29.470940Z","iopub.status.idle":"2023-08-18T13:17:29.478057Z","shell.execute_reply.started":"2023-08-18T13:17:29.470904Z","shell.execute_reply":"2023-08-18T13:17:29.476960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_classes = pred_probs.argmax(axis =1)\nprint(pred_classes)\nprint(class_names[pred_classes[0]])","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:40:16.555646Z","iopub.execute_input":"2023-08-18T12:40:16.556018Z","iopub.status.idle":"2023-08-18T12:40:16.563167Z","shell.execute_reply.started":"2023-08-18T12:40:16.555986Z","shell.execute_reply":"2023-08-18T12:40:16.562004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_labels = []\nfor image,label in test_data.unbatch():\n    y_labels.append(label.numpy().argmax())\ny_labels[:20]","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:40:16.565426Z","iopub.execute_input":"2023-08-18T12:40:16.566267Z","iopub.status.idle":"2023-08-18T12:40:26.980815Z","shell.execute_reply.started":"2023-08-18T12:40:16.566228Z","shell.execute_reply":"2023-08-18T12:40:26.979694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(pred_classes))\nprint(len(y_labels))","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:40:26.982212Z","iopub.execute_input":"2023-08-18T12:40:26.983235Z","iopub.status.idle":"2023-08-18T12:40:26.989259Z","shell.execute_reply.started":"2023-08-18T12:40:26.983195Z","shell.execute_reply":"2023-08-18T12:40:26.987967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(\"Classification report\\n\",classification_report(y_labels,pred_classes))","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:40:26.990926Z","iopub.execute_input":"2023-08-18T12:40:26.991493Z","iopub.status.idle":"2023-08-18T12:40:27.377426Z","shell.execute_reply.started":"2023-08-18T12:40:26.991458Z","shell.execute_reply":"2023-08-18T12:40:27.372597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classification_dict = classification_report(y_labels,pred_classes,output_dict = True)\nclassification_dict","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:40:27.378810Z","iopub.execute_input":"2023-08-18T12:40:27.379223Z","iopub.status.idle":"2023-08-18T12:40:27.401938Z","shell.execute_reply.started":"2023-08-18T12:40:27.379183Z","shell.execute_reply":"2023-08-18T12:40:27.400697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classification_f1_scores = {}\nfor k,v in classification_dict.items():\n    if k == \"accuracy\":\n        break\n    else:\n        classification_f1_scores[class_names[int(k)]] = v[\"f1-score\"]\nclassification_f1_scores","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:40:27.404887Z","iopub.execute_input":"2023-08-18T12:40:27.405594Z","iopub.status.idle":"2023-08-18T12:40:27.415608Z","shell.execute_reply.started":"2023-08-18T12:40:27.405552Z","shell.execute_reply":"2023-08-18T12:40:27.413812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_scores = pd.DataFrame({\"class_name\":list(classification_f1_scores.keys()),\n                         \"F1-Scores\":list(classification_f1_scores.values())})\nf1_scores.sort_values(\"F1-Scores\",ascending = False)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:40:27.417137Z","iopub.execute_input":"2023-08-18T12:40:27.417596Z","iopub.status.idle":"2023-08-18T12:40:27.577655Z","shell.execute_reply.started":"2023-08-18T12:40:27.417559Z","shell.execute_reply":"2023-08-18T12:40:27.576502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> From the F1-Scores dataframe we can clearly see that our model perform best on Melanocytic Nevi with an F1-Score of 0.92 and perform the worst on Atopic Dematitis.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport itertools\n\ndef make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False): \n  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n\n  If classes is passed, confusion matrix will be labelled, if not, integer class values\n  will be used.\n\n  Args:\n    y_true: Array of truth labels (must be same shape as y_pred).\n    y_pred: Array of predicted labels (must be same shape as y_true).\n    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n    figsize: Size of output figure (default=(10, 10)).\n    text_size: Size of output figure text (default=15).\n    norm: normalize values or not (default=False).\n    savefig: save confusion matrix to file (default=False).\n  \n  Returns:\n    A labelled confusion matrix plot comparing y_true and y_pred.\n\n  Example usage:\n    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n                          y_pred=y_preds, # predicted labels\n                          classes=class_names, # array of class label names\n                          figsize=(15, 15),\n                          text_size=10)\n  \"\"\"  \n  # Create the confustion matrix\n  cm = confusion_matrix(y_true, y_pred)\n  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n  n_classes = cm.shape[0] # find the number of classes we're dealing with\n\n  # Plot the figure and make it pretty\n  fig, ax = plt.subplots(figsize=figsize)\n  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n  fig.colorbar(cax)\n\n  # Are there a list of classes?\n  if classes:\n    labels = classes\n  else:\n    labels = np.arange(cm.shape[0])\n  \n  # Label the axes\n  ax.set(title=\"Confusion Matrix\",\n         xlabel=\"Predicted label\",\n         ylabel=\"True label\",\n         xticks=np.arange(n_classes), # create enough axis slots for each class\n         yticks=np.arange(n_classes), \n         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n         yticklabels=labels)\n  \n  # Make x-axis labels appear on bottom\n  ax.xaxis.set_label_position(\"bottom\")\n  ax.xaxis.tick_bottom()\n\n  ### Added: Rotate xticks for readability & increase font size (required due to such a large confusion matrix)\n  plt.xticks(rotation=70, fontsize=text_size)\n  plt.yticks(fontsize=text_size)\n\n  # Set the threshold for different colors\n  threshold = (cm.max() + cm.min()) / 2.\n\n  # Plot the text on each cell\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    if norm:\n      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n              horizontalalignment=\"center\",\n              color=\"white\" if cm[i, j] > threshold else \"black\",\n              size=text_size)\n    else:\n      plt.text(j, i, f\"{cm[i, j]}\",\n              horizontalalignment=\"center\",\n              color=\"white\" if cm[i, j] > threshold else \"black\",\n              size=text_size)\n\n  # Save the figure to the current working directory\n  if savefig:\n    fig.savefig(\"confusion_matrix.png\")","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:40:27.579694Z","iopub.execute_input":"2023-08-18T12:40:27.580443Z","iopub.status.idle":"2023-08-18T12:40:27.600957Z","shell.execute_reply.started":"2023-08-18T12:40:27.580398Z","shell.execute_reply":"2023-08-18T12:40:27.599879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_confusion_matrix(y_labels,pred_classes,classes = class_names,figsize = (20,20))","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:40:27.604704Z","iopub.execute_input":"2023-08-18T12:40:27.605894Z","iopub.status.idle":"2023-08-18T12:40:28.804883Z","shell.execute_reply.started":"2023-08-18T12:40:27.605852Z","shell.execute_reply":"2023-08-18T12:40:28.803885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* > From the confusion matrix we can clearly observe that the model is getting confused betwwen Melanocytic Nevi and Melanoma, Melanocyctic Nevi and Benign Kerotosis like Lesions, Tinea Ringworm Candidiasis and other Fungai Infections and Psoriasis pictures Lichen Planus and releated diseases.\n* > In order to examine why our model is getting confused between the above mentioned diseases we can look at the data ourselves or consult a doctor to find out whethere these disesase can be classified properly just by looking at their images, often when it comes to skin diseases it cannot be classified properly just by looking at the image further testing is required.","metadata":{}},{"cell_type":"markdown","source":"**Let us see what our most wrong predictions are to understand more about our model's performance**","metadata":{}},{"cell_type":"code","source":"filepaths = []\nfor filepath in test_data.list_files(f\"./{output}/test/*/*.jpg\", \n                                     shuffle=False):\n  filepaths.append(filepath.numpy())\nfilepaths[:10]","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:40:28.806413Z","iopub.execute_input":"2023-08-18T12:40:28.807493Z","iopub.status.idle":"2023-08-18T12:40:29.083729Z","shell.execute_reply.started":"2023-08-18T12:40:28.807452Z","shell.execute_reply":"2023-08-18T12:40:29.082715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_df = pd.DataFrame({\"img_path\": filepaths,\n                        \"y_true\": y_labels,\n                        \"y_pred\": pred_classes,\n                        \"pred_conf\": pred_probs.max(axis=1), # get the maximum prediction probability value\n                        \"y_true_classname\": [class_names[i] for i in y_labels],\n                        \"y_pred_classname\": [class_names[i] for i in pred_classes]}) \nprediction_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:40:29.085249Z","iopub.execute_input":"2023-08-18T12:40:29.085605Z","iopub.status.idle":"2023-08-18T12:40:29.106146Z","shell.execute_reply.started":"2023-08-18T12:40:29.085576Z","shell.execute_reply":"2023-08-18T12:40:29.105192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_df[\"correct_pred\"] = prediction_df[\"y_true\"]==prediction_df[\"y_pred\"]\nprediction_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:40:29.107874Z","iopub.execute_input":"2023-08-18T12:40:29.108616Z","iopub.status.idle":"2023-08-18T12:40:29.142633Z","shell.execute_reply.started":"2023-08-18T12:40:29.108575Z","shell.execute_reply":"2023-08-18T12:40:29.140850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_50_wrong = prediction_df[prediction_df[\"correct_pred\"] == False].sort_values(\"pred_conf\", ascending=False)[:50]\ntop_50_wrong.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T06:33:40.761662Z","iopub.execute_input":"2023-08-25T06:33:40.762197Z","iopub.status.idle":"2023-08-25T06:33:40.886526Z","shell.execute_reply.started":"2023-08-25T06:33:40.762150Z","shell.execute_reply":"2023-08-25T06:33:40.883893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.saved_model.save(model, \"skin_disease_saved_model\")\nmodel.save(\"skin_disease_model.h5\", overwrite=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T12:41:06.439670Z","iopub.execute_input":"2023-08-18T12:41:06.440139Z","iopub.status.idle":"2023-08-18T12:43:03.864626Z","shell.execute_reply.started":"2023-08-18T12:41:06.440096Z","shell.execute_reply":"2023-08-18T12:43:03.861444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dump the state of kaggle","metadata":{}},{"cell_type":"code","source":"# import dill\n# dill.dump_session('/kaggle/working/state.db')","metadata":{"execution":{"iopub.status.busy":"2023-08-18T13:45:38.685695Z","iopub.execute_input":"2023-08-18T13:45:38.686690Z","iopub.status.idle":"2023-08-18T13:45:38.691439Z","shell.execute_reply.started":"2023-08-18T13:45:38.686652Z","shell.execute_reply":"2023-08-18T13:45:38.689966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import inspect\n\n# for name, obj in inspect.getmembers(globals()):\n#     print(name)  \n#     if inspect.isfunction(obj) and inspect.isrecursive(obj):\n#         print(name)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-18T13:11:31.151828Z","iopub.execute_input":"2023-08-18T13:11:31.152228Z","iopub.status.idle":"2023-08-18T13:11:31.159191Z","shell.execute_reply.started":"2023-08-18T13:11:31.152198Z","shell.execute_reply":"2023-08-18T13:11:31.158060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# load the state of kaggle `state.db`","metadata":{}},{"cell_type":"code","source":"# import dill\n# dill.load_session('/kaggle/working/state.db')","metadata":{"execution":{"iopub.status.busy":"2023-08-18T11:20:59.671057Z","iopub.execute_input":"2023-08-18T11:20:59.671484Z","iopub.status.idle":"2023-08-18T11:20:59.780181Z","shell.execute_reply.started":"2023-08-18T11:20:59.671448Z","shell.execute_reply":"2023-08-18T11:20:59.778763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# create zip of saved model","metadata":{}},{"cell_type":"code","source":"!ls\n!rm skin_disease_saved_model.zip\n!zip -r /kaggle/working/skin_disease_saved_model.zip /kaggle/working/skin_disease_saved_model","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:26:13.066085Z","iopub.execute_input":"2023-08-21T06:26:13.066542Z","iopub.status.idle":"2023-08-21T06:26:26.629017Z","shell.execute_reply.started":"2023-08-21T06:26:13.066494Z","shell.execute_reply":"2023-08-21T06:26:26.627662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nprint(os.getcwd())\n!ls ../","metadata":{"execution":{"iopub.status.busy":"2023-08-29T12:44:10.704016Z","iopub.execute_input":"2023-08-29T12:44:10.704596Z","iopub.status.idle":"2023-08-29T12:44:11.910001Z","shell.execute_reply.started":"2023-08-29T12:44:10.704551Z","shell.execute_reply":"2023-08-29T12:44:11.908423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'skin_disease_saved_model.zip')","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:42:28.286001Z","iopub.execute_input":"2023-08-21T06:42:28.286408Z","iopub.status.idle":"2023-08-21T06:42:28.295722Z","shell.execute_reply.started":"2023-08-21T06:42:28.286371Z","shell.execute_reply":"2023-08-21T06:42:28.294557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(r'skin_disease_model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-08-21T06:42:30.587352Z","iopub.execute_input":"2023-08-21T06:42:30.587726Z","iopub.status.idle":"2023-08-21T06:42:30.595463Z","shell.execute_reply.started":"2023-08-21T06:42:30.587691Z","shell.execute_reply":"2023-08-21T06:42:30.594390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# load model and evaluate testing data","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Load the model using the TensorFlow SavedModel format\nloaded_saved_model = tf.saved_model.load(\"skin_disease_saved_model\")\n\n# Load the model using the Keras HDF5 format\nloaded_h5_model = load_model(\"skin_disease_model.h5\")\n\n# Compile the loaded model with new configurations\nloaded_h5_model.compile(\n    loss=tf.keras.losses.CategoricalCrossentropy(),\n    optimizer=tf.keras.optimizers.Adam(),\n    metrics=[\"accuracy\"]\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-29T04:52:13.791454Z","iopub.execute_input":"2023-08-29T04:52:13.791870Z","iopub.status.idle":"2023-08-29T04:52:54.806724Z","shell.execute_reply.started":"2023-08-29T04:52:13.791835Z","shell.execute_reply":"2023-08-29T04:52:54.805639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python --version","metadata":{"execution":{"iopub.status.busy":"2023-08-25T06:38:03.519677Z","iopub.execute_input":"2023-08-25T06:38:03.520095Z","iopub.status.idle":"2023-08-25T06:38:04.585822Z","shell.execute_reply.started":"2023-08-25T06:38:03.520058Z","shell.execute_reply":"2023-08-25T06:38:04.584553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # evaluate testing data\n# test_results_h5 = loaded_h5_model.evaluate(test_data)\n\n# # print(\"Test results (SavedModel):\", test_results_saved)\n# print(\"Test results (HDF5):\", test_results_h5)","metadata":{"execution":{"iopub.status.busy":"2023-08-18T09:44:34.325914Z","iopub.execute_input":"2023-08-18T09:44:34.326296Z","iopub.status.idle":"2023-08-18T09:44:58.300653Z","shell.execute_reply.started":"2023-08-18T09:44:34.326258Z","shell.execute_reply":"2023-08-18T09:44:58.299474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ../input/individual-images","metadata":{"execution":{"iopub.status.busy":"2023-08-25T06:45:21.752894Z","iopub.execute_input":"2023-08-25T06:45:21.754136Z","iopub.status.idle":"2023-08-25T06:45:22.848703Z","shell.execute_reply.started":"2023-08-25T06:45:21.754089Z","shell.execute_reply":"2023-08-25T06:45:22.847470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nimport numpy as np\nfrom tensorflow.keras.applications.vgg16 import decode_predictions","metadata":{"execution":{"iopub.status.busy":"2023-08-29T04:54:50.585813Z","iopub.execute_input":"2023-08-29T04:54:50.586570Z","iopub.status.idle":"2023-08-29T04:54:50.593871Z","shell.execute_reply.started":"2023-08-29T04:54:50.586532Z","shell.execute_reply":"2023-08-29T04:54:50.592658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef image_predict(image_path=None, model=None):\n    # Path to the single test image file\n    single_image_path = image_path\n\n    # Load and preprocess the image\n    img = image.load_img(single_image_path, target_size=(224, 224))\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n    img_array /= 255.0  # Normalize the image pixel values\n    \n    # Predict using the model\n    predictions = model.predict(img_array)\n    \n    # The predictions will contain probabilities for each class\n    print(\"Predicted probabilities:\", predictions)\n    # Get the index of the predicted class\n    pred = [[1.0070900e-05, 3.9449986e-04, 8.2579613e-01, 5.3181608e-05, 3.7938682e-04,\n  1.0911715e-01, 4.4978820e-02, 5.4754537e-06, 1.8970979e-02, 2.9431484e-04]]\n    predicted_class_index = np.argmax(predictions[0])\n#     predicted_class_name = class_names[predicted_class_index]\n#     print(\"Predicted class:\", predicted_class_name)\n#     return predicted_class_name\n    \n    \n\n    # Convert the predictions to a NumPy array\n#     predictions_array = np.array(pred)\n\n    # Calculate the percentages\n#     predicted_percentages = predictions_array * 100\n\n#     normalized_predictions = (predictions_array / np.sum(predictions_array)) * 100\n#     print(normalized_predictions)\n\n    # Calculate the percentage based on the maximum predicted probability\n    predicted_probability = predictions[0][predicted_class_index]\n    predicted_percentage = predicted_probability * 100\n#     max_predicted_probability = np.max(pred[0])\n#     print(predicted_probability, max_predicted_probability)\n#     predicted_percentage = (predicted_probability / max_predicted_probability) * 100\n    print(predicted_percentage)\n    rounded_percentage = round(predicted_percentage, 2)\n    print(rounded_percentage)\n\n\n\n#     print(results)\n\nprint(image_predict(\"/kaggle/input/disease4/ISIC_0066759.jpg\",model=loaded_h5_model))","metadata":{"execution":{"iopub.status.busy":"2023-08-29T05:34:43.449495Z","iopub.execute_input":"2023-08-29T05:34:43.449892Z","iopub.status.idle":"2023-08-29T05:34:43.598911Z","shell.execute_reply.started":"2023-08-29T05:34:43.449858Z","shell.execute_reply":"2023-08-29T05:34:43.597886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Retrain the model by using previous trained model**","metadata":{}},{"cell_type":"markdown","source":"# Get newly training, validation and testing datasets","metadata":{}},{"cell_type":"code","source":"# Specify the folders you want to copy\nnew_train_dir = \"new_train_data\"\nfolders_to_retrain = [\"10. Warts Molluscum and other Viral Infections - 2103\",\"7. Psoriasis pictures Lichen Planus and related diseases - 2k\"]  # Replace with the actual folder names\nnum_classification = len(folders_to_retrain)\ngenerate_output_dir(output=new_train_dir)\ngenerate_datasets(folders_to_retrain, loc=input_location, output=new_train_dir)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T09:04:37.853652Z","iopub.execute_input":"2023-08-17T09:04:37.854398Z","iopub.status.idle":"2023-08-17T09:05:06.460296Z","shell.execute_reply.started":"2023-08-17T09:04:37.854354Z","shell.execute_reply":"2023-08-17T09:05:06.459247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"# plot new dataset\nplot_random_figures(loc=folders_to_retrain, output=new_train_dir)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T09:05:24.743979Z","iopub.execute_input":"2023-08-17T09:05:24.744377Z","iopub.status.idle":"2023-08-17T09:05:25.026788Z","shell.execute_reply.started":"2023-08-17T09:05:24.744344Z","shell.execute_reply":"2023-08-17T09:05:25.025803Z"}}},{"cell_type":"code","source":"\ntrain_dir_re = f\"./{new_train_dir}/train\"\ntest_dir_re =  f\"./{new_train_dir}/test\"\nval_dir_re = f\"./{new_train_dir}/val\"\n\ntrain_data_re, test_data_re, val_data_re = generate_train_test_validation(train_dir_re, test_dir_re, val_dir_re)\ntrain_data_re, test_data_re, val_data_re = auto_tune_data(train_data_re, test_data_re, val_data_re)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T09:06:35.861055Z","iopub.execute_input":"2023-08-17T09:06:35.863935Z","iopub.status.idle":"2023-08-17T09:06:36.375275Z","shell.execute_reply.started":"2023-08-17T09:06:35.863892Z","shell.execute_reply":"2023-08-17T09:06:36.374145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the loaded model with new configurations\ncompile_model(loaded_h5_model)\n\n# Assuming you have new_train_data and new_val_data for retraining\nhistory_retrain = loaded_h5_model.fit(\n    new_train_data,\n    epochs=15,\n    steps_per_epoch=len(new_train_data),\n    validation_data=new_val_data,\n    validation_steps=int(0.25 * len(new_val_data)),\n    callbacks=[early_stop, reduce_lr]\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-17T09:06:06.094141Z","iopub.execute_input":"2023-08-17T09:06:06.094548Z","iopub.status.idle":"2023-08-17T09:06:06.100052Z","shell.execute_reply.started":"2023-08-17T09:06:06.094516Z","shell.execute_reply":"2023-08-17T09:06:06.098881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get versions of imported packages\n# import some packages to check\n\nimport pkg_resources\nimport types\ndef get_imports():\n    for name, val in globals().items():\n        if isinstance(val, types.ModuleType):\n            # Split ensures you get root package, \n            # not just imported function\n            name = val.__name__.split(\".\")[0]\n\n        elif isinstance(val, type):\n            name = val.__module__.split(\".\")[0]\n\n        # Some packages are weird and have different\n        # imported names vs. system names\n        if name == \"PIL\":\n            name = \"Pillow\"\n        elif name == \"sklearn\":\n            name = \"scikit-learn\"\n\n        yield name\nimports = list(set(get_imports()))\n\nrequirements = []\nfor m in pkg_resources.working_set:\n    if m.project_name in imports and m.project_name!=\"pip\":\n        requirements.append((m.project_name, m.version))\n\nfor r in requirements:\n    print(\"{}=={}\".format(*r))","metadata":{"execution":{"iopub.status.busy":"2023-08-21T05:14:36.809873Z","iopub.execute_input":"2023-08-21T05:14:36.810328Z","iopub.status.idle":"2023-08-21T05:14:36.825600Z","shell.execute_reply.started":"2023-08-21T05:14:36.810293Z","shell.execute_reply":"2023-08-21T05:14:36.824136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip show protobuf","metadata":{"execution":{"iopub.status.busy":"2023-08-21T10:16:20.573068Z","iopub.execute_input":"2023-08-21T10:16:20.573520Z","iopub.status.idle":"2023-08-21T10:16:33.583812Z","shell.execute_reply.started":"2023-08-21T10:16:20.573457Z","shell.execute_reply":"2023-08-21T10:16:33.582500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}